<!-- python 100本ノック 学習用のファイル -->

<!--

import os
from google.colab import drive
drive.mount('/content/drive')

///   knock41   ///  データ読み込み、整形

import pandas as pd
customer = pd.read_csv("/content/drive/My Drive/100knock/customer_join4.csv")
uselog_months = pd.read_csv("/content/drive/My Drive/100knock/use_log_months4.csv")


year_months = list(uselog_months["年月"].unique())
uselog = pd.DataFrame()
for i in range(1, len(year_months)):
  tmp = uselog_months.loc[uselog_months["年月"] == year_months[i]].copy()
  tmp.rename(columns = {"count":"count_0"}, inplace = True)
  tmp_before = uselog_months.loc[uselog_months["年月"] == year_months[i-1]].copy()
  del tmp_before["年月"]
  tmp_before.rename(columns = {"count":"count_1"}, inplace = True)
  tmp = pd.merge(tmp, tmp_before, on = "customer_id", how = "left")
  uselog = pd.concat([uselog, tmp], ignore_index = True)
uselog.head()

短期退会者の傾向をつかむため、一か月前の状況から予測する


/// /// /// /// ///


///   knock42   ///  退会者、退会前月のデータ

from dateutil.relativedelta import relativedelta
exit_customer = customer.loc[customer["is_deleted"] == 1].copy()
exit_customer["exit_date"] = None
exit_customer["end_date"] = pd.to_datetime(exit_customer["end_date"])
for i in exit_customer.index:
  exit_customer.loc[i, "exit_date"] = exit_customer.loc[i, "end_date"] - relativedelta(months = 1)
exit_customer["exit_date"] = pd.to_datetime(exit_customer["exit_date"])
exit_customer["年月"] = exit_customer["exit_date"].dt.strftime("%Y%m")
uselog["年月"] = uselog["年月"].astype(str)
exit_uselog = pd.merge(uselog, exit_customer, on = ["customer_id", "年月"], how = "left")
print(len(uselog))
exit_uselog.head()

退会者に絞り込み
退会付きの一か月前の年月を取得
結合



exit_uselog = exit_uselog.dropna(subset = ["name"])
print(len(exit_uselog))
print(len(exit_uselog["customer_id"].unique()))
exit_uselog.head()

欠損値除去

/// /// /// /// ///



///   knock43   ///  継続客のデータ

conti_customer = customer.loc[customer["is_deleted"] == 0]
conti_uselog = pd.merge(uselog, conti_customer, on = ["customer_id"], how = "left")
print(len(conti_uselog))
conti_uselog = conti_uselog.dropna(subset = ["name"])
print(len(conti_uselog))

継続客だけを抽出、結合
conti_customer = customer.loc[customer["is_deleted"] == 0]
conti_uselog = pd.merge(uselog, conti_customer, on = ["customer_id"], how = "left")

データ数確認
print(len(conti_uselog))

name列欠損データを削除
conti_uselog = conti_uselog.dropna(subset = ["name"])

削除後のデータ数確認
print(len(conti_uselog))

conti_uselog = conti_uselog.sample(frac = 1, random_state = 0).reset_index(drop = True)
conti_uselog = conti_uselog.drop_duplicates(subset = "customer_id")
print(len(conti_uselog))
conti_uselog.head()

退会者データ数に比べて継続者データ数は多いので、数を近づける
データをシャッフル
conti_uselog = conti_uselog.sample(frac = 1, random_state = 0).reset_index(drop = True)

重複を削除
conti_uselog = conti_uselog.drop_duplicates(subset = "customer_id")
print(len(conti_uselog))
conti_uselog.head()


predict_data = pd.concat([conti_uselog, exit_uselog], ignore_index = True)
print(len(predict_data))
predict_data.head()
継続客データと退会者データを縦に結合


/// /// /// /// ///



///   knock44   ///  予測する月の在籍期間確認

predict_data["period"] = 0
predict_data["now_date"] = pd.to_datetime(predict_data["年月"], format = "%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])
for i in range(len(predict_data)):
  delta = relativedelta(predict_data.loc[i, "now_date"], predict_data.loc[i, "start_date"])
  predict_data.loc[i, "period"] = int(delta.years * 12 + delta.months)
predict_data.head()

在籍期間列の追加
在籍期間は年月とstart_date列の差から算出

/// /// /// /// ///


///   knock45   ///  欠損値除去

predict_data.isna().sum()
欠損値があると機械学習はできない
欠損値を確認
数字が0ではないものが欠損値

predict_data = predict_data.dropna(subset = ["count_1"])
predict_data.isna().sum()

dropna は subset で指定した列を除外できる

/// /// /// /// ///



///   knock46   ///  カテゴリカル変数

target_col = ["campaign_name", "class_name", "gender", "count_1", "routine_flg", "period", "is_deleted"]
predict_data = predict_data[target_col]
predict_data.head()


ダミー変数
predict_data = pd.get_dummies(predict_data)
predict_data.head()


不要列削除
del predict_data["campaign_name_通常"]
del predict_data["class_name_ナイト"]
del predict_data["gender_M"]
predict_data.head()

/// /// /// /// ///


///   knock47   ///  退会予測モデル作成 決定木

from sklearn.tree import DecisionTreeClassifier
import sklearn.model_selection
exit = predict_data.loc[predict_data["is_deleted"] == 1]
conti = predict_data.loc[predict_data["is_deleted"] == 0].sample(len(exit), random_state = 0)
X = pd.concat([exit, conti], ignore_index = True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)
model = DecisionTreeClassifier(random_state = 0)
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)
print(y_test_pred)

ライブラリ導入
from sklearn.tree import DecisionTreeClassifier
import sklearn.model_selection

退会者と継続者のデータ数を合わせる
exit = predict_data.loc[predict_data["is_deleted"] == 1]
conti = predict_data.loc[predict_data["is_deleted"] == 0].sample(len(exit), random_state = 0)

学習データと評価データの分割
X = pd.concat([exit, conti], ignore_index = True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)

モデル定義、評価データの予測、出力
model = DecisionTreeClassifier(random_state = 0)
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)
print(y_test_pred)


result_test = pd.DataFrame({"y_test":y_test, "y_pred":y_test_pred})
result_test.head()
実測値と予測値の比較

/// /// /// /// ///




-->