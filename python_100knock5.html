<!-- python 100本ノック 学習用のファイル -->

<!--

import os
from google.colab import drive
drive.mount('/content/drive')

///   knock41   ///  データ読み込み、整形

import pandas as pd
customer = pd.read_csv("/content/drive/My Drive/100knock/customer_join4.csv")
uselog_months = pd.read_csv("/content/drive/My Drive/100knock/use_log_months4.csv")


year_months = list(uselog_months["年月"].unique())
uselog = pd.DataFrame()
for i in range(1, len(year_months)):
  tmp = uselog_months.loc[uselog_months["年月"] == year_months[i]].copy()
  tmp.rename(columns = {"count":"count_0"}, inplace = True)
  tmp_before = uselog_months.loc[uselog_months["年月"] == year_months[i-1]].copy()
  del tmp_before["年月"]
  tmp_before.rename(columns = {"count":"count_1"}, inplace = True)
  tmp = pd.merge(tmp, tmp_before, on = "customer_id", how = "left")
  uselog = pd.concat([uselog, tmp], ignore_index = True)
uselog.head()

短期退会者の傾向をつかむため、一か月前の状況から予測する


/// /// /// /// ///


///   knock42   ///  退会者、退会前月のデータ

from dateutil.relativedelta import relativedelta
exit_customer = customer.loc[customer["is_deleted"] == 1].copy()
exit_customer["exit_date"] = None
exit_customer["end_date"] = pd.to_datetime(exit_customer["end_date"])
for i in exit_customer.index:
  exit_customer.loc[i, "exit_date"] = exit_customer.loc[i, "end_date"] - relativedelta(months = 1)
exit_customer["exit_date"] = pd.to_datetime(exit_customer["exit_date"])
exit_customer["年月"] = exit_customer["exit_date"].dt.strftime("%Y%m")
uselog["年月"] = uselog["年月"].astype(str)
exit_uselog = pd.merge(uselog, exit_customer, on = ["customer_id", "年月"], how = "left")
print(len(uselog))
exit_uselog.head()

退会者に絞り込み
退会付きの一か月前の年月を取得
結合



exit_uselog = exit_uselog.dropna(subset = ["name"])
print(len(exit_uselog))
print(len(exit_uselog["customer_id"].unique()))
exit_uselog.head()

欠損値除去

/// /// /// /// ///



///   knock43   ///  継続客のデータ

conti_customer = customer.loc[customer["is_deleted"] == 0]
conti_uselog = pd.merge(uselog, conti_customer, on = ["customer_id"], how = "left")
print(len(conti_uselog))
conti_uselog = conti_uselog.dropna(subset = ["name"])
print(len(conti_uselog))

継続客だけを抽出、結合
conti_customer = customer.loc[customer["is_deleted"] == 0]
conti_uselog = pd.merge(uselog, conti_customer, on = ["customer_id"], how = "left")

データ数確認
print(len(conti_uselog))

name列欠損データを削除
conti_uselog = conti_uselog.dropna(subset = ["name"])

削除後のデータ数確認
print(len(conti_uselog))

conti_uselog = conti_uselog.sample(frac = 1, random_state = 0).reset_index(drop = True)
conti_uselog = conti_uselog.drop_duplicates(subset = "customer_id")
print(len(conti_uselog))
conti_uselog.head()

退会者データ数に比べて継続者データ数は多いので、数を近づける
データをシャッフル
conti_uselog = conti_uselog.sample(frac = 1, random_state = 0).reset_index(drop = True)

重複を削除
conti_uselog = conti_uselog.drop_duplicates(subset = "customer_id")
print(len(conti_uselog))
conti_uselog.head()


predict_data = pd.concat([conti_uselog, exit_uselog], ignore_index = True)
print(len(predict_data))
predict_data.head()
継続客データと退会者データを縦に結合


/// /// /// /// ///



///   knock44   ///  予測する月の在籍期間確認

predict_data["period"] = 0
predict_data["now_date"] = pd.to_datetime(predict_data["年月"], format = "%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])
for i in range(len(predict_data)):
  delta = relativedelta(predict_data.loc[i, "now_date"], predict_data.loc[i, "start_date"])
  predict_data.loc[i, "period"] = int(delta.years * 12 + delta.months)
predict_data.head()

在籍期間列の追加
在籍期間は年月とstart_date列の差から算出

/// /// /// /// ///


///   knock45   ///  欠損値除去

predict_data.isna().sum()
欠損値があると機械学習はできない
欠損値を確認
数字が0ではないものが欠損値

predict_data = predict_data.dropna(subset = ["count_1"])
predict_data.isna().sum()

dropna は subset で指定した列を除外できる

/// /// /// /// ///



///   knock46   ///  カテゴリカル変数

target_col = ["campaign_name", "class_name", "gender", "count_1", "routine_flg", "period", "is_deleted"]
predict_data = predict_data[target_col]
predict_data.head()


ダミー変数
predict_data = pd.get_dummies(predict_data)
predict_data.head()


不要列削除
del predict_data["campaign_name_通常"]
del predict_data["class_name_ナイト"]
del predict_data["gender_M"]
predict_data.head()

/// /// /// /// ///


///   knock47   ///  退会予測モデル作成 決定木

from sklearn.tree import DecisionTreeClassifier
import sklearn.model_selection
exit = predict_data.loc[predict_data["is_deleted"] == 1]
conti = predict_data.loc[predict_data["is_deleted"] == 0].sample(len(exit), random_state = 0)
X = pd.concat([exit, conti], ignore_index = True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)
model = DecisionTreeClassifier(random_state = 0)
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)
print(y_test_pred)

ライブラリ導入
from sklearn.tree import DecisionTreeClassifier
import sklearn.model_selection

退会者と継続者のデータ数を合わせる
exit = predict_data.loc[predict_data["is_deleted"] == 1]
conti = predict_data.loc[predict_data["is_deleted"] == 0].sample(len(exit), random_state = 0)

学習データと評価データの分割
X = pd.concat([exit, conti], ignore_index = True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)

モデル定義、評価データの予測、出力
model = DecisionTreeClassifier(random_state = 0)
model.fit(X_train, y_train)
y_test_pred = model.predict(X_test)
print(y_test_pred)


results_test = pd.DataFrame({"y_test":y_test, "y_pred":y_test_pred})
results_test.head()
実測値と予測値の比較

/// /// /// /// ///



///   knock48   ///  予測モデル評価

correct = len(results_test.loc[results_test["y_test"] == results_test["y_pred"]])
data_count = len(results_test)
score_test = correct / data_count
print(score_test)

実測値と予測値が同じデータを確認、カウント
correct = len(results_test.loc[results_test["y_test"] == results_test["y_pred"]])
data_count = len(results_test)

正答率
score_test = correct / data_count
print(score_test)

print(model.score(X_test, y_test))
print(model.score(X_train, y_train))
関数での正答率算出

評価データの正答率
print(model.score(X_test, y_test))

学習データの正答率
print(model.score(X_train, y_train))

学習データの精度＞評価データの精度
→ 学習データに適合しすぎている → 過学習の傾向


X = pd.concat([exit, conti], ignore_index = True)
y = X["is_deleted"]
del X["is_deleted"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)
model = DecisionTreeClassifier(random_state = 0, max_depth = 5)
model.fit(X_train, y_train)
print(model.score(X_test, y_test))
print(model.score(X_train, y_train))

決定木の深さを浅くしモデルの簡易化を実施
学習データ評価データの差が小さくなった


/// /// /// /// ///


///   knock49   ///  各変数の寄与

importance = pd.DataFrame({"feature_names":X.columns, "coefficient":model.feature_importances_})
importance

変数取得関数
model.feature_importances_

決定木の可視化
!pip install japanize_matplotlib
from sklearn import tree
import matplotlib.pyplot as plt
import japanize_matplotlib
%matplotlib inline
plt.figure(figsize = (20, 8))
tree.plot_tree(model, feature_names = X.columns, fontsize = 8)

日本語化
!pip install japanize_matplotlib

決定木の可視化
tree.plot_tree(model, feature_names = X.columns, fontsize = 8)

/// /// /// /// ///



///   knock50   ///  

count_1 = 3
routine_flg = 1
period = 10
campaign_name = "入会費無料"
class_name = "オールタイム"
gender = "M"


if campaign_name == "入会費半額":
    campaign_name_list = [1, 0]
elif campaign_name == "入会費無料":
    campaign_name_list = [0, 1]
elif campaign_name == "通常":
    campaign_name_list = [0, 0]
if class_name == "オールタイム":
    class_name_list = [1, 0]
elif class_name == "デイタイム":
    class_name_list = [0, 1]
elif class_name == "ナイト":
    class_name_list = [0, 0]
if gender == "F":
    gender_list = [1]
elif gender == "M":
    gender_list = [0]
input_data = [count_1, routine_flg, period]
input_data.extend(campaign_name_list)
input_data.extend(class_name_list)
input_data.extend(gender_list)
input_data = pd.DataFrame(data = [input_data], columns = X.columns)

カテゴリカル変数作成
ダミー変数へ変換


print(model.predict(input_data))
print(model.predict_proba(input_data))

推定結果
1なら退会、0なら継続
print(model.predict(input_data))

予測確率結果
print(model.predict_proba(input_data))


/// /// /// /// ///


-->