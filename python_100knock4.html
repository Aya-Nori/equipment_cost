<!-- python 100本ノック 学習用のファイル -->

<!--

import os
from google.colab import drive
drive.mount('/content/drive')

///   knock31   ///  データ概要確認

import pandas as pd
uselog = pd.read_csv("/content/drive/My Drive/100knock/use_log4.csv")
uselog.isnull().sum()


customer = pd.read_csv("/content/drive/My Drive/100knock/customer_join4.csv")
customer.isnull().sum()

データ読み込みと欠損値の確認実施

/// /// /// /// ///


///   knock32   ///  クラスタリング、データのグループ化


customer_clustering = customer[["mean", "median", "max", "min", "membership_period"]]
customer_clustering.head()
顧客データグループ化のため、変数絞り込み



from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
customer_clustering_sc = sc.fit_transform(customer_clustering)

kmeans = KMeans(n_clusters = 4, random_state = 0)
clusters = kmeans.fit(customer_clustering_sc)
customer_clustering = customer_clustering.assign(cluster = clusters.labels_)

print(customer_clustering["cluster"].unique())
customer_clustering.head()

K-means法、標準化のためのscikit-learnライブラリ導入
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

標準化実行、新たに格納
sc = StandardScaler()
customer_clustering_sc = sc.fit_transform(customer_clustering)

K-meansのモデル構築、クラスタ数＝4とし、モデル定義
kmeans = KMeans(n_clusters = 4, random_state = 0)
clusters = kmeans.fit(customer_clustering_sc)
customer_clustering = customer_clustering.assign(cluster = clusters.labels_)

0-3の4グループが作成された


/// /// /// /// ///


///   knock33   ///  クラスタ結果

customer_clustering.columns = ["月内平均値", "月内中央値", "月内最大値", "月内最小値", "会員期間", "cluster"]
customer_clustering.groupby("cluster").count()

列名の変更
customer_clustering.columns = ["月内平均値", "月内中央値", "月内最大値", "月内最小値", "会員期間", "cluster"]

列をクラスタごとに集計
customer_clustering.groupby("cluster").count()

グループごとの平均
customer_clustering.groupby("cluster").mean()


/// /// /// /// ///


///   knock34   /// グラフ表示

from sklearn.decomposition import PCA
X = customer_clustering_sc
pca = PCA(n_components = 2)
pca.fit(X)
x_pca = pca.transform(X)
pca_df = pd.DataFrame(x_pca)
pca_df["cluster"] = customer_clustering["cluster"]

主成分分析
ライブラリ導入
from sklearn.decomposition import PCA

モデル定義
pca = PCA(n_components = 2)

主成分分析実施
pca.fit(X)
x_pca = pca.transform(X)

pca_df：二次元に削減したデータを格納


import matplotlib.pyplot as plt
%matplotlib inline
for i in customer_clustering["cluster"].unique():
  tmp = pca_df.loc[pca_df["cluster"] == i]
  plt.scatter(tmp[0], tmp[1])

ライブラリ導入
import matplotlib.pyplot as plt

グラフ表示
%matplotlib inline

散布図にプロット
for i in customer_clustering["cluster"].unique():
  tmp = pca_df.loc[pca_df["cluster"] == i]
  plt.scatter(tmp[0], tmp[1])


/// /// /// /// ///



///   knock35   ///  退会者の傾向把握

customer_clustering = pd.concat([customer_clustering, customer], axis = 1)
customer_clustering.groupby(["cluster", "is_deleted"], as_index = False).count()[["cluster", "is_deleted", "customer_id"]]

データ結合
customer_clustering = pd.concat([customer_clustering, customer], axis = 1)

各クラスタでの集計
customer_clustering.groupby(["cluster", "is_deleted"], as_index = False).count()[["cluster", "is_deleted", "customer_id"]]

定期利用の確認
customer_clustering.groupby(["cluster", "routine_flg"], as_index = False).count()[["cluster", "routine_flg", "customer_id"]]


/// /// /// /// ///



///   knock36   ///  翌月の利用回数予測のための準備

uselog["usedate"] = pd.to_datetime(uselog["usedate"])
uselog["年月"] = uselog["usedate"].dt.strftime("%Y%m")
uselog_months = uselog.groupby(["年月", "customer_id"], as_index = False).count()
uselog_months.rename(columns = {"log_id":"count"}, inplace = True)
del uselog_months["usedate"]
uselog_months.head()


year_months = list(uselog_months["年月"].unique())
predict_data = pd.DataFrame()
for i in range(6, len(year_months)):
  tmp = uselog_months.loc[uselog_months["年月"] == year_months[i]].copy()
  tmp.rename(columns = {"count":"count_pred"}, inplace = True)
  for j in range(1, 7):
    tmp_before = uselog_months.loc[uselog_months["年月"] == year_months[i-j]].copy()
    del tmp_before["年月"]
    tmp_before.rename(columns = {"count":"count_{}".format(j-1)}, inplace = True)
    tmp = pd.merge(tmp, tmp_before, on = "customer_id", how = "left")
  predict_data = pd.concat([predict_data, tmp], ignore_index = True)
predict_data.head()


欠損値の除去
predict_data = predict_data.dropna()
predict_data = predict_data.reset_index(drop = True)
predict_data.head()


/// /// /// /// ///



///   knock37   ///  変数付与

predict_data = pd.merge(predict_data, customer[["customer_id", "start_date"]], on = "customer_id", how = "left")
predict_data.head()
会員期間を得るため、入会日をリストに追加した


predict_data["now_date"] = pd.to_datetime(predict_data["年月"], format="%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])
from dateutil.relativedelta import relativedelta
predict_data["period"] = None
for i in range(len(predict_data)):
    delta = relativedelta(predict_data.loc[i, "now_date"].to_pydatetime(), predict_data.loc[i, "start_date"].to_pydatetime())
    predict_data.loc[i, "period"] = delta.years * 12 + delta.months
predict_data.head()
日数計算

以下、テキストと異なるため、注意
    delta = relativedelta(predict_data.loc[i, "now_date"].to_pydatetime(), predict_data.loc[i, "start_date"].to_pydatetime())


/// /// /// /// ///



///   knock38   ///  変予測モデル作成

predict_data = predict_data.loc[predict_data["start_date"] >= pd.to_datetime("20180401")]
from sklearn import linear_model
import sklearn.model_selection
model = linear_model.LinearRegression()
X = predict_data[["count_0", "count_1", "count_2", "count_3", "count_4", "count_5", "period"]]
y = predict_data["count_pred"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)
model.fit(X_train, y_train)


2018/4/1以降の顧客を選択
predict_data = predict_data.loc[predict_data["start_date"] >= pd.to_datetime("20180401")]

sklearn用ライブラリとデータ分割用ライブラリに読み込み
from sklearn import linear_model
import sklearn.model_selection

モデル初期化、変数定義
model = linear_model.LinearRegression()
X = predict_data[["count_0", "count_1", "count_2", "count_3", "count_4", "count_5", "period"]]
y = predict_data["count_pred"]

データ分割（無指定では学習データ75％、評価データ25％）
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, random_state = 0)
model.fit(X_train, y_train)


回帰モデルの精度
print(model.score(X_train, y_train))
print(model.score(X_test, y_test))
[出力結果*100]％というふうに読む


/// /// /// /// ///


///   knock39   ///  変数確認

coef = pd.DataFrame({"feature_names":X.columns, "coefficient":model.coef_})
coef

説明変数ごとに寄与している変数の係数を出力する
出力された数字が大きいほど、寄与が大きい


/// /// /// /// ///





-->